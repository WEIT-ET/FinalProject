# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yCqdkmQZ9bm6G64NsQC1tY-URBKM1-Xu
"""


from collections import defaultdict
import pandas as pd
import numpy as np
from omegaconf import OmegaConf
import os
import random
import pickle
from sklearn.preprocessing import LabelEncoder
import tqdm

from sklearn.model_selection import StratifiedKFold, KFold
from catboost import CatBoostRegressor
from sklearn.metrics import mean_squared_error

cfg = OmegaConf.load('weit.yaml')

def setSeeds(seed=cfg.train.seed):
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)

setSeeds()



train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")

def preprocess_location(df):
    df["Location"] = df["Location"].str.replace(r'[^0-9a-zA-Z:,]','')

    df["location_city"] = df["Location"].apply(lambda x:x.split(",")[0].strip())
    df["location_state"] = df["Location"].apply(lambda x:x.split(",")[1].strip())
    df["location_country"] = df["Location"].apply(lambda x:x.split(",")[2].strip())

    df = df.replace("na", "None")
    df = df.replace("", "None")

    return df

train = preprocess_location(train)
test = preprocess_location(test)

pre_city = set(train["location_city"]) & set(train["location_country"])
pre_city.remove("None")
pre_state = set(train["location_state"]) & set(train["location_country"])
pre_state.remove("None")

grouped_state = train.groupby(["location_state", "location_country"]).count().sort_values(by="ID", ascending=False)["ID"].reset_index()

state = defaultdict(str)

for row, value in grouped_state.iterrows():
    if state[value["location_state"]] == "":
        del state[value["location_state"]]
        if value["location_country"] in pre_state:
            state[value["location_state"]] = value["location_country"]


grouped_city = train.groupby(["location_city", "location_country"]).count().sort_values(by="ID", ascending=False)["ID"].reset_index()

city = defaultdict(str)

for idx, value in grouped_city.iterrows():
    if city[value["location_city"]] == "":
        del city[value["location_city"]]
        if value["location_country"] in pre_city:
            city[value["location_city"]] = value["location_country"]

city.update(state)

def map_country(row):
    if row in city.keys():
        return city[row]
    else:
        return row

def preprocess_country(data):
    data["location_country"] = data["location_country"].apply(lambda x: map_country(x))

preprocess_country(train)
preprocess_country(test)

def preprocess_age(row):
    if row <= 10:
        return 0
    elif row <= 20:
        return 1
    elif row <= 30:
        return 2
    elif row <= 40:
        return 3
    elif row <= 50:
        return 4
    elif row <=60:
        return 5
    elif row <=70:
        return 6
    else:
        return 7

def preprocess_year2(row):
    if row == -1:
        return 0
    elif row < 1990:
        return 1900
    elif row > 2021:
        return 2021
    else:
        return int(row)

def make_label():
    for cat in cfg.data.cat_features:
        le = LabelEncoder()
        train[cat] = train[cat].astype('category')
        train[cat] = le.fit_transform(train[[cat]])
        with open(f"{cat}_le.pkl","wb") as f:
            pickle.dump(le, f)

def test_label():
    for cat in cfg.data.cat_features:
        test[cat] = test[cat].astype('category')
        with open(f"{cat}_le.pkl","rb") as f:
            le = pickle.load(f)
        #새로운 x_test 데이터 추가
        for label in tqdm.tqdm(set(test[cat])):
            if label not in le.classes_:
                le.classes_ = np.append(le.classes_, label)
        test[cat] = le.transform(test[[cat]])

preprocess_country(train)
preprocess_country(test)

train["Age"] = train["Age"].apply(lambda x:preprocess_age(x))
test["Age"] = test["Age"].apply(lambda x:preprocess_age(x))

train["Year-Of-Publication"] = train["Year-Of-Publication"].apply(lambda x:preprocess_year2(x))
test["Year-Of-Publication"] = test["Year-Of-Publication"].apply(lambda x:preprocess_year2(x))

make_label()
test_label()

train_data = train[cfg.data.use_features]
train_data["label"] = train[cfg.data.label]
test_data = test[cfg.data.use_features]

skf = StratifiedKFold(n_splits = 10, shuffle = True)
rmse = 0

features = train_data.drop(["label"], axis=1)
label = train_data["label"]

sub_preds = np.zeros(test_data.shape[0])


import optuna
from optuna.samplers import TPESampler

data = {}
sub_data = pd.read_csv("sample_submission.csv")

def objective(trial):
    param = {
        "random_state":2024,
        "objective" : "RMSE",
        "cat_features" :  cfg.model.cat_features,
        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.01, 0.5),
        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),
        "n_estimators":trial.suggest_int("n_estimators", 1000, 10000),
        "max_depth":trial.suggest_int("max_depth", 4, 16),
        'random_strength' :trial.suggest_int('random_strength', 0, 100),
        "l2_leaf_reg":trial.suggest_float("l2_leaf_reg",1e-8,3e-5),
        "min_child_samples": trial.suggest_int("min_child_samples", 5, 100),
        "max_bin": trial.suggest_int("max_bin", 200, 500),
        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),
    }

    model = CatBoostRegressor(**param, eval_metric="RMSE")

    model.fit(data["x_train"], data["y_train"], eval_set = [(data["x_valid"], data["y_valid"])],
        cat_features = cfg.model.cat_features,
        verbose = False)

    _predict = model.predict(data["x_valid"])
    _rmse = np.sqrt(mean_squared_error(_predict, data["y_valid"]))

    return _rmse

for idx, (train_idx, valid_idx) in enumerate(skf.split(features, label)):
    print(f'--------------- FOLD-{idx}, INIT {cfg.model.model_name} ---------------')
    data["x_train"], data["x_valid"] = features.iloc[train_idx], features.iloc[valid_idx]
    data["y_train"], data["y_valid"] = label.iloc[train_idx], label.iloc[valid_idx]


    ################### hyper parameter tuning ##############
    sampler = optuna.samplers.TPESampler(seed=2024)
    study = optuna.create_study(
        study_name = 'cat_parameter_opt',
        direction = 'minimize',
        sampler = sampler,
    )
    study.optimize(objective, n_trials=5)


    model = CatBoostRegressor(**study.best_params, random_state = 2024, objective = 'RMSE',
                        cat_features = cfg.model.cat_features)

    model.fit(data["x_train"], data["y_train"], eval_set = [(data["x_valid"], data["y_valid"])])

    pred = model.predict(test_data)
    sub_data[f'pred_{idx}'] = pred

    print(f'================================================================================\n\n')
    ##########################################################

    sub_data["Book-Rating"] = (sub_data["pred_0"] + sub_data["pred_1"] + sub_data["pred_2"] + sub_data["pred_3"] + sub_data["pred_4"]) / 5
    sub_data.to_csv("tuning_cbm.csv", index=False)